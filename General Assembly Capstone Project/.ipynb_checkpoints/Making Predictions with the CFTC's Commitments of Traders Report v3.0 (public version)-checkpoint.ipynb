{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is a model I am actually using to try to make accurate bets in the futures market, I have masked some of my data from public view. However, I would like to share my thought process, and explain what I did to get my results.\n",
    "\n",
    "For context, I was examining data from the CFTC's Commitments of Traders Report to find out for myself if the legends of the report's predictive accuracy were true. Could mining this report for patterns and correlations allow the financial data analyst to make predictions with any kind of accuracy? I spent some time going through the report and testing the covariance between certain variables and the next week's change of price. I found that there does seem be a connection between the two, enough of one that with blind testing on data my model had not seen, it was able to predict the next week's change of price (up or down) with 64% accuracy. \n",
    "\n",
    "After achieving this result, I used Principle Component Analysis to decompose the data into the five variables you see below. There's not a lot of interpretability there, so if you would like to predict price direction with the report yourself, the data is out there. I got my price data using the Chicago Mercantile Exchange api at quandl.com (a terrific website for financial data streams), and you can find the Commitments of Traders Report historical data at: http://www.cftc.gov/MarketReports/CommitmentsofTraders. They have all the data preserved in CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model_df = pd.read_csv('pca_transformed_xvars.csv')\n",
    "y_vars = pd.read_csv('price_changes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.163114</td>\n",
       "      <td>1.079553</td>\n",
       "      <td>-0.126914</td>\n",
       "      <td>0.270626</td>\n",
       "      <td>0.098197</td>\n",
       "      <td>-0.328149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.667378</td>\n",
       "      <td>0.056017</td>\n",
       "      <td>0.050201</td>\n",
       "      <td>-1.076702</td>\n",
       "      <td>-0.176977</td>\n",
       "      <td>-0.197070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.963460</td>\n",
       "      <td>0.805376</td>\n",
       "      <td>-0.768775</td>\n",
       "      <td>-0.293738</td>\n",
       "      <td>0.057174</td>\n",
       "      <td>0.110143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.464611</td>\n",
       "      <td>0.590830</td>\n",
       "      <td>-0.156438</td>\n",
       "      <td>0.795129</td>\n",
       "      <td>-0.548107</td>\n",
       "      <td>-0.064407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.067147</td>\n",
       "      <td>0.149905</td>\n",
       "      <td>0.102411</td>\n",
       "      <td>-0.476938</td>\n",
       "      <td>0.632868</td>\n",
       "      <td>0.788675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3         4         5\n",
       "0           0  2.163114  1.079553 -0.126914  0.270626  0.098197 -0.328149\n",
       "1           1  3.667378  0.056017  0.050201 -1.076702 -0.176977 -0.197070\n",
       "2           2  2.963460  0.805376 -0.768775 -0.293738  0.057174  0.110143\n",
       "3           3  1.464611  0.590830 -0.156438  0.795129 -0.548107 -0.064407\n",
       "4           4  1.067147  0.149905  0.102411 -0.476938  0.632868  0.788675"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.head() #here are my decomposed X variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  0\n",
       "0           0  1\n",
       "1           1  1\n",
       "2           2  0\n",
       "3           3  0\n",
       "4           4  0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vars.head() #this is my price change data. The two categories are 'Down' and 'Up' as you will see in my models below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I used a random forest model, which is essentially a bootstrap-aggregated decision tree model. It carves the data up into categories, and then subcategories, and then sub-subcategories. It then uses these groupings to predict on unseen data. It does this multiple times in order to correct any mistakes it makes for a given iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 1}\n",
      "0.574850299401\n",
      "Random Forest Score:\t0.513 Â± 0.029\n",
      "[[ 0.95        0.05      ]\n",
      " [ 0.905       0.095     ]\n",
      " [ 0.86        0.14      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.87        0.13      ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.89666667  0.10333333]\n",
      " [ 0.94        0.06      ]\n",
      " [ 0.3         0.7       ]\n",
      " [ 0.87        0.13      ]\n",
      " [ 0.93        0.07      ]\n",
      " [ 0.12        0.88      ]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.87        0.13      ]\n",
      " [ 0.49452381  0.50547619]\n",
      " [ 0.64        0.36      ]\n",
      " [ 0.48333333  0.51666667]\n",
      " [ 0.76        0.24      ]\n",
      " [ 0.07488095  0.92511905]\n",
      " [ 1.          0.        ]\n",
      " [ 0.87        0.13      ]\n",
      " [ 0.59        0.41      ]\n",
      " [ 0.13654762  0.86345238]\n",
      " [ 0.43        0.57      ]\n",
      " [ 0.75333333  0.24666667]\n",
      " [ 0.87        0.13      ]\n",
      " [ 0.21        0.79      ]\n",
      " [ 0.9         0.1       ]\n",
      " [ 0.58        0.42      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.77        0.23      ]\n",
      " [ 0.97        0.03      ]\n",
      " [ 0.585       0.415     ]\n",
      " [ 0.11        0.89      ]\n",
      " [ 0.4         0.6       ]\n",
      " [ 0.88        0.12      ]\n",
      " [ 0.67        0.33      ]\n",
      " [ 0.765       0.235     ]\n",
      " [ 0.49        0.51      ]\n",
      " [ 0.14        0.86      ]\n",
      " [ 0.65        0.35      ]\n",
      " [ 0.87        0.13      ]\n",
      " [ 0.595       0.405     ]\n",
      " [ 0.73        0.27      ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.72        0.28      ]\n",
      " [ 0.2         0.8       ]\n",
      " [ 0.86666667  0.13333333]\n",
      " [ 0.90166667  0.09833333]\n",
      " [ 0.89        0.11      ]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.2         0.8       ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.86333333  0.13666667]\n",
      " [ 0.4         0.6       ]\n",
      " [ 0.605       0.395     ]\n",
      " [ 0.19        0.81      ]\n",
      " [ 0.2         0.8       ]\n",
      " [ 0.9         0.1       ]\n",
      " [ 0.13654762  0.86345238]\n",
      " [ 0.66        0.34      ]\n",
      " [ 0.01        0.99      ]\n",
      " [ 0.19        0.81      ]\n",
      " [ 0.81        0.19      ]\n",
      " [ 0.93        0.07      ]\n",
      " [ 0.38        0.62      ]\n",
      " [ 0.68        0.32      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.44        0.56      ]\n",
      " [ 0.09        0.91      ]\n",
      " [ 0.37        0.63      ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.325       0.675     ]\n",
      " [ 0.64        0.36      ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.25        0.75      ]\n",
      " [ 0.49        0.51      ]\n",
      " [ 0.17        0.83      ]\n",
      " [ 0.47754762  0.52245238]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.74        0.26      ]\n",
      " [ 0.335       0.665     ]\n",
      " [ 0.61        0.39      ]\n",
      " [ 0.5175      0.4825    ]\n",
      " [ 0.31        0.69      ]\n",
      " [ 0.82766667  0.17233333]\n",
      " [ 0.99        0.01      ]\n",
      " [ 0.04        0.96      ]\n",
      " [ 0.82        0.18      ]\n",
      " [ 0.5075      0.4925    ]\n",
      " [ 0.17        0.83      ]\n",
      " [ 0.27        0.73      ]\n",
      " [ 0.07        0.93      ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.48        0.52      ]\n",
      " [ 0.865       0.135     ]\n",
      " [ 0.805       0.195     ]\n",
      " [ 0.69166667  0.30833333]\n",
      " [ 0.31        0.69      ]\n",
      " [ 0.33        0.67      ]\n",
      " [ 0.76        0.24      ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.02        0.98      ]\n",
      " [ 0.71        0.29      ]\n",
      " [ 0.11        0.89      ]\n",
      " [ 0.43        0.57      ]\n",
      " [ 0.48497619  0.51502381]\n",
      " [ 0.96        0.04      ]\n",
      " [ 0.9         0.1       ]\n",
      " [ 0.93        0.07      ]\n",
      " [ 0.49        0.51      ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.73        0.27      ]\n",
      " [ 0.91        0.09      ]\n",
      " [ 0.67        0.33      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.71        0.29      ]\n",
      " [ 0.18        0.82      ]\n",
      " [ 0.12        0.88      ]\n",
      " [ 0.28        0.72      ]\n",
      " [ 0.73333333  0.26666667]\n",
      " [ 0.03        0.97      ]\n",
      " [ 0.7         0.3       ]\n",
      " [ 0.19        0.81      ]\n",
      " [ 0.36333333  0.63666667]\n",
      " [ 0.755       0.245     ]\n",
      " [ 0.83333333  0.16666667]\n",
      " [ 0.98        0.02      ]\n",
      " [ 0.34        0.66      ]\n",
      " [ 0.24        0.76      ]\n",
      " [ 1.          0.        ]\n",
      " [ 0.67        0.33      ]\n",
      " [ 0.96166667  0.03833333]\n",
      " [ 0.13        0.87      ]\n",
      " [ 0.67        0.33      ]\n",
      " [ 0.41        0.59      ]\n",
      " [ 0.86633333  0.13366667]\n",
      " [ 0.62        0.38      ]\n",
      " [ 0.08        0.92      ]\n",
      " [ 0.68        0.32      ]\n",
      " [ 0.34        0.66      ]\n",
      " [ 0.95        0.05      ]\n",
      " [ 0.17        0.83      ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 0.922       0.078     ]\n",
      " [ 0.75        0.25      ]\n",
      " [ 0.829       0.171     ]\n",
      " [ 0.93        0.07      ]\n",
      " [ 0.59        0.41      ]\n",
      " [ 0.11        0.89      ]\n",
      " [ 0.72        0.28      ]\n",
      " [ 0.32        0.68      ]\n",
      " [ 0.59        0.41      ]\n",
      " [ 0.89        0.11      ]\n",
      " [ 0.73        0.27      ]\n",
      " [ 0.86666667  0.13333333]\n",
      " [ 0.05        0.95      ]\n",
      " [ 0.18        0.82      ]\n",
      " [ 0.61        0.39      ]\n",
      " [ 0.36        0.64      ]\n",
      " [ 0.75583333  0.24416667]\n",
      " [ 0.27        0.73      ]\n",
      " [ 0.23        0.77      ]\n",
      " [ 0.22        0.78      ]\n",
      " [ 0.09333333  0.90666667]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "y = y_vars['0']\n",
    "\n",
    "X = model_df[['0', '1', '2', '3', '4', '5']]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "cv = StratifiedKFold(Y_train, n_folds=3, shuffle=True, random_state=41)\n",
    "\n",
    "rt = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "param_grid = { \n",
    "     'max_depth' : [None, 1, 3, 5, 7, 10]\n",
    "}\n",
    "CV_rt = GridSearchCV(estimator=rt, param_grid=param_grid, cv= 5)\n",
    "CV_rt.fit(X_train, Y_train)\n",
    "print CV_rt.best_params_\n",
    "rt.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = rt.predict_proba(X_test)\n",
    "Y_plot = rt.predict(X_test)\n",
    "\n",
    "print rt.score(X_test, Y_test)\n",
    "s = cross_val_score(rt, X_train, Y_train, cv=cv, n_jobs=-1)\n",
    "print \"{} Score:\\t{:0.3} Â± {:0.3}\".format(\"Random Forest\", s.mean().round(3), s.std().round(3))\n",
    "\n",
    "print Y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest has an accuracy score of .51. This is not much better than random guessing. \n",
    "However, it becomes an important part of the ensemble model later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each week, the random forest model predicts whether the price will go down or up. Each of the following models does the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RF Price_Down  RF Price_Up\n",
      "0       0.950000     0.050000\n",
      "1       0.905000     0.095000\n",
      "2       0.860000     0.140000\n",
      "3       1.000000     0.000000\n",
      "4       0.870000     0.130000\n",
      "5       0.750000     0.250000\n",
      "6       0.990000     0.010000\n",
      "7       0.896667     0.103333\n",
      "8       0.940000     0.060000\n",
      "9       0.300000     0.700000\n"
     ]
    }
   ],
   "source": [
    "RT_pp = pd.DataFrame(rt.predict_proba(X_test), columns=['RF Price_Down','RF Price_Up'])\n",
    "print(RT_pp.iloc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61676646706586824"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "GNBmodel = GaussianNB().fit(X_train, Y_train)\n",
    "GNB_pp = pd.DataFrame(GNBmodel.predict_proba(X_test), columns=['NB Price_Down','NB Price_Up'])\n",
    "GNBmodel.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I use a Naive Bayes model to make predictions using the same data. Naive Bayes assumes independence for each variable and uses Bayes' theorem to attempt to determine how much each variable contributes to the probability of price going up/down. As you can see below, the predictions differ from the random forest model. This model is more accurate overall (by nearly 10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NB Price_Down  NB Price_Up\n",
      "0       0.562408     0.437592\n",
      "1       0.578966     0.421034\n",
      "2       0.484829     0.515171\n",
      "3       0.641979     0.358021\n",
      "4       0.456699     0.543301\n",
      "5       0.632247     0.367753\n",
      "6       0.632161     0.367839\n",
      "7       0.333357     0.666643\n",
      "8       0.704619     0.295381\n",
      "9       0.741286     0.258714\n"
     ]
    }
   ],
   "source": [
    "print(GNB_pp.iloc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60479041916167664"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnmodel = KNeighborsClassifier(n_neighbors=7).fit(X_train, Y_train)\n",
    "knn_pp = pd.DataFrame(knnmodel.predict_proba(X_test), columns=['KNN Price_Down','KNN Price_Up'])\n",
    "knnmodel.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Nearest Neighbors model above is comparable to Naive Bayes. This model saves all the training data to memory, and then for any given point, it counts the K points (in this case 7 points) nearest to it to determine the percent likelihood that that point is a \"price up\" vs. a \"price down\" point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59281437125748504"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model \n",
    "lr = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "lr.fit(X_train, Y_train)\n",
    "lr_pp = pd.DataFrame(lr.predict_proba(X_test), columns=['LR Price_Down','LR Price_Up'])\n",
    "lr.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And simple logistic regression also performs in the same ballpark (for non-stats people reading this, logistic regression is among the most commonly used models for predicting binary classes). All the models have similar accuracy overall, but when predicting any given week, there is a large spread. The models seldom agree with one another. \n",
    "\n",
    "Below, I created an ensemble model that leverages the variances of the different models to improve their collective score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66 25]\n",
      " [35 41]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.73      0.69        91\n",
      "          1       0.62      0.54      0.58        76\n",
      "\n",
      "avg / total       0.64      0.64      0.64       167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_df = pd.DataFrame()\n",
    "ensemble_df['RF Price_Down'] = RT_pp['RF Price_Down']\n",
    "ensemble_df['RF Price_Up'] = RT_pp['RF Price_Up']\n",
    "ensemble_df['NB Price_Down'] = GNB_pp['NB Price_Down']\n",
    "ensemble_df['NB Price_Up'] = GNB_pp['NB Price_Up']\n",
    "ensemble_df['KNN Price_Down'] = knn_pp['KNN Price_Down']\n",
    "ensemble_df['KNN Price_Up'] = knn_pp['KNN Price_Up']\n",
    "ensemble_df['LR Price_Down'] = lr_pp['LR Price_Down']\n",
    "ensemble_df['LR Price_Up'] = lr_pp['LR Price_Up']\n",
    "\n",
    "ensemble_df['Ensemble Price_Down'] = (ensemble_df['RF Price_Down'] + ensemble_df['NB Price_Down'] +\n",
    "                                      ensemble_df['KNN Price_Down'] + ensemble_df['LR Price_Down'])/4\n",
    "\n",
    "ensemble_df['Ensemble Price_Up'] = (ensemble_df['RF Price_Up'] + ensemble_df['NB Price_Up'] +\n",
    "                                      ensemble_df['KNN Price_Up'] + ensemble_df['LR Price_Up'])/4\n",
    "ensemble_df['pred_class_thresh50'] = [1 if x >= 0.5 else 0 for x in ensemble_df['Ensemble Price_Up'].values]\n",
    "\n",
    "confusion = np.array(confusion_matrix(Y_test, ensemble_df['pred_class_thresh50']))\n",
    "print(confusion)\n",
    "print(classification_report(Y_test, ensemble_df['pred_class_thresh50']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "64% using the ensemble method! By averaging all the models, we see a 3-10% boost in accuracy across them all. This may not sound great, but in the futures market, any accuracy score above 50% means that you're winning more often than you're losing, which is the best we can ask for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
